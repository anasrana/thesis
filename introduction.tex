% -*- root: warwickthesis.tex -*-

\chapter{Introduction}
\label{cha:introduction}

Biological systems have been studied for centuries, motivated by both fundamental questions concerning living systems, and by medical applications. Mathematical and physical principles have long been understood to underpin biological phenomena \citep{Lotka:1925tu, Rashevsky:1935jt}. In recent years,  widespread use of mathematical, computational and physical approaches for biological investigation has gathered pace, partly due to technological advances that permit quantitative study of biomolecular systems. Moreover, computational advances allow for more efficient modelling and simulation of such systems.
% Mathematics other than basic principles has only been applied to biology in recent years considering the long history of coexistence of the two fields.
Possibly one of the most successful application of mathematical and physical ideas to a biological problem can be found in neuroscience, starting from basic principles of current flow in axons to the propagation of action potentials in neurons first studied in a
% one of the first applications of mathematics in biology was the study of the current flow through the
squid axon by \cite{Hodgkin:1952td}. After this remarkable breakthrough, further development in the field included increased involvement of mathematical ideas. A number of advancements have been made which would have been unthinkable without the influence of mathematics in the field \citep{Amari201348}.

The last two decades have seen an increase in the availability of high throughput data driven by technological advancements and the decrease in cost \citep{Schadt:2010dp}. This in turn has lead to the increased need of mathematical techniques to fully understand phenomena underlying observed data. Simply observing and analysing the abundant data available is not an effective method,
as even measuring a single sample can include data with thousands of components and comparing them manually is unreasonable.
Additionally it has been determined that an approach of studying each component of the system independently is not sufficient for detailed understanding.
% Genes interact with each other and so do proteins and any other component in the cell.
The cell contains many regulatory components most important are genes and proteins. Interactions exist between components of the same type as well as between components of different types.
This leads to a tremendous number of interactions that needs to be understood, increasing the need for an approach including biological experiments as well as expertise in mathematics, statistics, physics and engineering.

In physics, the use of mathematics alongside experiments has allowed for a more profound understanding of physical phenomena. As an example, classical mechanics allows a relatively simple description of macro phenomena, even though we know that some of the assumptions do not always hold we can still make accurate predictions. On the other hand, we have the description of micro phenomena described by quantum mechanics. However, even though it is possible to describe macro phenomena using quantum mechanics there is no need to include that detail. %In a similar fashion
Analogous to physics, in biology intracellular and intercellular interactions that lead to disease can be deduced without a full understanding of all the elements involved in its description. Approaching this problem from the other direction, it is possible to study interactions of simple genes and proteins, as these interactions are not yet fully understood. It is therefore not possible to say if such an approach will eventually allow the description of cell level behaviour. Unlike physics, in biological systems there is still work needed for both approaches.

An extremely important process universal in many areas of biology is the transformation of cells from one type to another: cell differentiation \citep{Tang:2010ed, Vierbuchen:2010fa}, stem cell reprogramming \citep{Takahashi:2006hi, Hanna:2010jy}, and disease formation \citep{Hannah:2000wo, Vogel:2010jb} to name but a few. These changes can be on the genetic level, on a protein level, or even on an epigenetic\footnote{see Section \ref{sec:cell} for a more detailed discussion on epigenetics} level. The transitions can be driven or initiated by very small perturbations in the form of induced genes. For such a system single-cell stochasticity is a very powerful concept and has been observed in a variety of experimental settings, such as E. coli  \citep{Elowitz:2002hb} and stem cell reprogramming \citep{Hanna:2009ix}. Since stochastic transitions, occur on a single-cell level, at any time during a transition the cell population as a whole exists in a mixture of states. Moreover, the exact composition of this mixture changes over time. Any measurements performed on homogenates\footnote{mixture obtained from mechanically broken down cells} from this population results in population averages with unknown composition. Trivially the best strategy would be to measure at the single-cell level. Despite advancements in genome-wide single-cell measurements \citep{deSouza:2012dz, Tang:2011gt} there remain challenges including limited availability of such data and limits to the number of genes that can be measured. Furthermore, such measurements do not allow live tracking of cells and in fact the measurement process itself destroys cells thereby breaking continuity (i.e. the next measurement is on a different set of cells). These are the reasons for an incomplete understanding of transition processes. Therefore understanding transformation processes from aggregated data is important.

Inevitably, an important question arises here about our definition of states in the transformation. There are many ways to approach this and an obvious way is to define states in a biological sense, but there is no consensus on a biologically motivated definition of a state. In a biological sense a complete definition of a state would include all possible information regarding the state, if we don't include the different stages of the cell cycle as distinct states we have to define an area in this complex space as some changes in the cell will be due to inherent noise or the cell cycle. In most cases, not all information is available or is limited due to cost. In this work when we talk about states, we are referring to changes in gene expression to a number of genes across the genome.

The study of stem cell reprogramming plays an important role in the development of personalised medicine, which in its extreme would allow the regrowth of whole organs to replace damaged ones. This could circumvent any issues arising from treatments derived using foreign cells, as treatments would originate from the patients own cells. Work carried out in this field has yielded the development of techniques that allow the development of neurons from embryonic stem cells \citep{Vierbuchen:2010fa, Pang:2011ce} or creating muscle cells \citep{Ieda:2010ir, Efe:2011bpa}. These processes could become even more powerful when the starting point is a differentiated cell harvested from the patient \citep{Takahashi:2006hi}. There are still unanswered questions in this field about the differences of cells derived from differentiated cells to cells derived directly from embryonic stem cells \citep{Carey:2011bs, Bock:2011kx}. A better understanding of the transformation process would help in identifying issues and could propose potential ways of improving the transformation process.

Cancer is a disease so prevalent in modern society that in the UK the lifetime chance of contracting cancer is more than one in three \citep{Sasieni:2011}. The disease has its source in multiple genetic mutations causing changes to natural cell functions such as cell proliferation and apoptosis\footnote{programmed cell-death}, which transforms cells from a healthy state to a cancerous state. These mutations code for proteins that are implicated in the eight hallmarks of cancer \citep{Hanahan:2011gu}. The hallmarks are the circumvention for the need of external growth signals; cells are unaffected by external growth-inhibition signals; evasion of apoptosis; unlimited replication; the potential to create additional blood vessels from existing ones; invasion of other tissue types; energy management of the cell and avoiding the bodies immune response. Understanding the transformation process that changes a healthy cell population to a cancerous one would allow intervention target at specific genes and proteins.

The cell cycle is central to the proliferation of cells and hence plays a key role in both transformations mentioned above. In fact mutations that can lead to cancer can be acquired during the cell cycle as this is the process during which DNA is replicated and the replication process can at times lead to errors. In a normal cell there are multiple checks that prevent such errors from propagating, but in an unhealthy cell genes central to these processes are mutated leading to malfunctions. Radiation plays an important role in the cell as it can be a cause of mutations and is also used as treatment to kill unhealthy cells; damage to DNA can lead to apoptosis during the cell cycle. Radiation effects on the cell include changes in gene expression and are also related to radiation strength \citep{Gentile:2003in}. Some cells will arrest in the cell cycle after radiation damage either leading to apoptosis or a brief pause in the cell cycle followed by a re-entry to the cell cycle \citep{Pawlik2004928}. Understanding the mechanism that leads to the different responses is key in treatment as well as prevention of cancer.

In this thesis we attempt to learn single-cell level information from homogenate population averaged data of various types. We especially focus on gene expression and the role of genes in transformation. We take a data driven approach where model parameters are estimated by comparison to data. The first model we use is based on latent Markov processes aggregated over cells using a least squares estimation; it takes inspiration from the success in application of latent variable models such as hidden Markov models (HMMs) to hidden transitions in biology and genomics \citep{Yoon:2009dl,Ernst:2012iia}. The second model uses simple statistical principles for the derivation of the model and Monte Carlo integration to approximate an integral. These are simple models that allow investigation of complicated biological processes.

% =====================================================================

HMM's have been successfully applied to study a variety of biological phenomena such as gene prediction, sequence alignment and RNA folding among many others \citep[and references therein]{Yoon:2009dl}. One of the most successful applications in recent times has been ChromeHMM \citep{Ernst:2012iia}.\footnote{In this and the following paragraphs some biological vocabulary will be used which is explained in Section \ref{sec:cell}} The model is focused on understanding epigenetic modification and their effect on gene expression. As we know DNA encodes genes, but epigenetic modifications enable interpretation of the information contained on DNA. It is responsible for huge diversity found in cells across the human body. Histones are proteins found in cells that order and package DNA and more than 100 distinct types of modifications to these proteins have been described. The modifications often are a variety of proteins binding to histone. It has been suggested that studying combinations of these modifications is of values as they encode biological functions \citep{strahl2000language}. An alternative suggestion is that the modifications are only additive and combinations have no effect \cite{schreiber2002signaling}.

\cite{Ernst:2010bh} outline a method to distinguish between these two possibilities. The input data they have available is the reads for binding of proteins along chromatin which they convert to a binary of bound or unbound signal for each protein.  They employ a multivariate HMM with which they capture two types of frequencies: the frequency of combinations of proteins found together on the genome and the frequency of the spatial relationship of states across the genome. The resulting output is a state assignment along the chromatin. Applying this model to human T cells\footnote{a type of white blood cell} they identify $51$ distinct states which they are able to link to distinct experimentally observed characteristics as well as functional groups. The genomic locations also correspond well to transcription start sites, transcription enhancing sites as well as active and repressed genes.  The most useful results from the analysis is a predictive model for states based on histone modifications which is tested on independent measurements on different systems.

% ____ NEXT par  ___

The kind of problem we wish to address in this thesis is to identify individual state parameters when measurements are only made on population averages. Methods that have a similar goal have been studied before with a variety of models and methods. These methods take very different approaches to address this question varying from simple deconvolution algorithm to more involved models based on HMM. We will examine a few of the suggested models here.

\cite{Bar-Joseph04082004} presents a deconvolution algorithm for cells that are initially synchronised by  stopping them in the cell cycle. In biological systems the synchronisation is not perfect and eventually cells fall out of synchronisation over time. It is developed to clean up the signal for yeast cells undergoing the cell cycle. The method presented is a deconvolution based on a cubic spline interpolation as an initial step to deal with missing data. The  parameters for the spline are estimated using an expectation-maximisation (EM) algorithm, which is an iterative method for finding the maximum likelihood in models with latent variables. As an input the method requires gene expression data for the cell cycle (a microarray time course is used in the application) as well as the budding\footnote{a form of asexual reproduction found in yeast} index. The budding index measures when the cell splits in two which allows this to act as a measure for the cells temporal position in the cell cycle. The problem studied here is somewhat simpler than a cellular transformation as yeast cells are relatively synchronised across two cell cycles and the genes considered follow a cyclic process.

\cite{Roy:2006ik} propose an approach that is based on a multinomial HMM (MHMM) which has distinct advantages to the previously used simple deconvolution approaches \citep{Bar-Joseph04082004,Lahdesmaki:2005fh}, it does not require specific prior information about individual states such as the gene expression of each cell or the distribution of cells in individual states. In this approach the hidden state represents the distribution of cells across all possible populations. The observed states represent measured gene expression in time. Parameter estimation is performed using an EM algorithm and the posterior distribution is estimated using a sequential Monte Carlo (SMC) approach\footnote{A SMC implements Bayesian recursion equations and is used when we wish to estimate posterior densities of the state variables from known observation variables.}. The model is applied to cell cycle data as well as simulation data. Since the latent state is in discrete time and assumes even distribution of time-points.

Existing models to study individual state parameters from population averaged data present some promising results. The approaches taken are often limited as the method is either tailored for a very specific application or it requires information in addition to the gene expression time course that allows for further knowledge about the states in the system. \cite{Roy:2006ik} present a model that does not have these short comings, it in fact aims to estimate a similar parameter as the one discussed in \ref{cha:stamm}. It does not provide information about the gene expression of individual states in the population and it imposes restrictions on the temporal distribution of data though it can handle missing data.

% =====================================================================

Chapter \ref{cha:stamm} starts with the description of a model called \emph{State Transitions using Aggregated Markov Models} (STAMM) based on previous work by \cite{Armond:2013}; a latent stochastic process that obtains state-specific gene expression data as well as number of intermediate states from homogenate population time courses. As discussed above there exist models with similar aims such as deconvolving the cell cycle by \cite{Bar-Joseph04082004}; dissecting expression data with known mixtures \citep{Lahdesmaki:2005fh}; or a hidden Markov model to determine expression levels and fractions of cells in each population \citep{Roy:2006ik}. Even though all such methods have strengths, they also contain weaknesses addressed by STAMM. Firstly, it provides single-cell level description of the transformations process and just like in the real system, this process is hidden from observation due to averaging over multiple realisations (or cells). Second, in our model the latent process is in continuous time and therefore there is no need for special techniques to deal with missing data and unevenly distributed measurements. Third, the model relies on very few assumptions such as fractions of mixtures; it estimates all parameters from data. We also discuss in this Chapter a single-cell level simulation process, which is used to test the model properties and assumptions. Then we also outline a computationally efficient model selection procedure following and expanding on previous work by \cite{Armond:2013}. Results show that parameter estimation works well even when violating assumptions. Only strong violations make estimations difficult and in this setting, transition rates in particular are not estimated well.

 Chapter \ref{cha:oncog-transf} describes an application of STAMM to RNA-seq time course data of an oncogenic transformation using a healthy breast cell line (MCF-10A) as the initial population. We outline the pre-processing steps needed to apply the model to RNA-seq data. Since observations are made as counts, it is often considered that a Poisson distribution or a negative binomial distribution is the most fitting to such data. However, we argue that once data has been pre-processed to allow for comparison between independent samples the data are no longer integer counts, but rather can be usefully treated as continuous. Then we show application of STAMM and show that it can be applied to large data sets in a relatively short computational time.

Chapter \ref{cha:stem-cells} briefly discusses results from applying STAMM to a microarray time course. This is obtained by  reprogramming of secondary Mouse embryonic fibroblast (MEF) cells to induced pluripotent stem cells. Then we show a possible next step once parameters have been obtained by STAMM. This step includes comparison of estimated parameters to new single-cell measurements, which in this case were carried out on a different reprogramming system \citep{Buganim:2012hp}. We show that results are comparable despite measurements being made on different systems and using different methods.

Chapter \ref{cha:cell-cycle} derives a model to investigate a slightly different system where less data is available and serves as a proof of concept since data was not available in time for this thesis. The gene expression is measured at the initial time point and the cell population is subject to a stimulus of various strengths. At a later time, fractions of cells in two distinct states are obtained by counting individual cells. An example of such a system is a population of cells radiated during the cell cycle upon which some go into arrest leading to apoptosis and some re-enter the cell cycle at a later time. This process is believed to be dependant on heterogeneity at the initial time point. This model attempts to assign a weight to each gene signifying its importance to the transformation process. Then we outline a single-cell simulation procedure and apply the model to a single gene simulation and a four gene simulation. Results show that a high noise level makes it difficult to estimate parameters but at low noise levels, parameters are estimated reasonably well allowing us to at least distinguish between genes that are important for transformation to ones that are not.

\vspace*{2cm}
\noindent Novel contributions of this thesis are listed below:
\begin{itemize}
\item {\bf Chapter \ref{cha:stamm}}
\begin{itemize}
\item Single-cell simulation study. We present a simulation framework imitating the biological single-cell processes; single-cells undergo transitions between states sampled from a statistical distribution and observed expressions are an average over cells. The strength of this approach is that single-cell state specific parameters for data generation are known. Therefore, we can empirically test estimation of parameters as well as the selection of correct number of states. It also allows us to check estimation under violation of model assumptions and additionally we can empirically investigate identifiability of the model.

\item Full investigation of estimation, including tuning parameters. We discuss and verify with simulations parameter estimation including setting tuning parameters using an unbiased approach. This is followed by sensitivity analysis performed for tuning parameters.

\item Computationally efficient model selection. For STAMM to be useful, an unbiased estimation of model parameters, especially the number of states, is important. We put forward a simple approach which uses a form of cross-validation to determine number of states and other model parameters. We show that this method is effective during simulation and computationally efficient.

\item Implementation in R. We wrote a package for the STAMM model in R including a simulated data set, published at \url{https://github.com/anasrana/stamm}.

\end{itemize}

\item {\bf Chapter \ref{cha:oncog-transf}}

\begin{itemize}
\item Application of STAMM to RNA-seq time-course data.
We show, using an example, how STAMM is able to analyse sequencing time-course data. The example we chose is using RNA-seq data from an {\it in vitro} study of oncogenic transformation of a healthy breast cancer cell line (MCF-10A) under induction of the oncogene {\it src}.

\end{itemize}
\item {\bf Chapter \ref{cha:stem-cells}}
  \begin{itemize}
  \item Comparing estimation to single-cell measurements for stem cell reprogramming. In this Chapter the main contribution is firstly, computational i.e. ensuring that estimation was reproducible as well as determining sensitivity of Bayesian model selection to the choice of hyper-parameters. Secondly, a comparison of estimated parameters from STAMM to single-cell level measurements taken at different time points.
  \end{itemize}

\item {\bf Chapter \ref{cha:cell-cycle}}
  \begin{itemize}
  \item Proof of concept of a novel model. Here, we introduce a new model to understand the importance of genes for radiation response. The gene expression is only measured for the initial population subsequent measurements are fractions of cells transforming at different radiation doses. We also outline a single-cell simulation set-up and a brief application of the model to simulated data.
  \end{itemize}
\end{itemize}



%%% Local Variables:
%%% TeX-master: "warwickthesis"
%%% End:
