% -*- root: warwickthesis.tex -*-

\chapter{Introduction}
\label{cha:introduction}

Biological systems have been studied for centuries, motivated by both fundamental questions concerning living systems, and by medical applications. Mathematical and physical principles have long been understood to underpin biological phenomena \citep{Lotka:1925tu, Rashevsky:1935jt}. In recent years,  widespread use of mathematical, computational and physical approaches for biological investigation has gathered pace, partly due to technological advances that permit quantitative study of biomolecular systems. Moreover computational advances allow for more efficient modelling and simulation of such systems.
% Mathematics other than basic principles has only been applied to biology in recent years considering the long history of coexistence of the two fields.
Possibly one of the most successful application of mathematical and physical ideas to a biological problem can be found in neuroscience, starting from basic principles of current flow in axons to the propagation of action potentials in neurons first studied in a
% one of the first applications of mathematics in biology was the study of the current flow through the
squid axon by \cite{Hodgkin:1952td}. After this remarkable breakthrough, further development in the field included increased involvement of mathematical ideas. A number advancements have been made which would have been unthinkable without the influence of mathematics in the field \citep{Amari201348}.

The last two decades have seen an increase in the availability of high throughput data driven by technological advancements and the decrease in cost \citep{Schadt:2010dp}. This in turn has lead to the increased need of mathematical techniques to fully understand phenomena underlying observed data. Simply observing and analysing the abundant data available is not an effective method,
as even measuring a single sample can include data with thousands of components and comparing them manually is unreasonable.
Additionally it has been determined that an approach of studying each component of the system independently is not sufficient for detailed understanding.
% Genes interact with each other and so do proteins and any other component in the cell.
The cell contains many regulatory components most important are genes and proteins. Interactions exist between components of the same type as well as between components of different types.
Additionally  interactions and regulatory connections also exist between different types of components. This has increased the need for an approach including biological experiments as well as expertise in mathematics, statistics, physics and engineering.

In physics the use of mathematics alongside experiments has allowed for a more profound understanding of physical phenomena. As an example classical mechanics allows a relatively simple description of macro phenomena, even though we know that some of the assumptions do not always hold we can still make accurate predictions. On the other hand we have the description of micro phenomena described by quantum mechanics. However, even though it is possible to describe macro phenomena using quantum mechanics there is no need to include that detail. %In a similar fashion
Analogous to physics, in biology intracellular and intercellular interactions that lead to disease can be deduced without a full understanding of all the elements involved in its description. Approaching this problem from the other direction, it is possible to study interactions of simple genes and proteins, as these interactions are not yet fully understood. It is therefore not possible to say if such an approach will eventually allow the description of cell level behaviour. Unlike physics, in biological systems there is still work needed for both approaches.

An extremely important process universal in many areas of biology is the transformation of cells from one type to another: cell differentiation \citep{Tang:2010ed, Vierbuchen:2010fa}, stem cell reprogramming \citep{Takahashi:2006hi, Hanna:2010jy}, and disease formation \citep{Hannah:2000wo, Vogel:2010jb} to name but a few. These changes can be on the genetic level, on a protein level, or even on an epigenetic level. The transitions can be driven or initiated by very small perturbations in the form of induced genes. For such a system single-cell stochasticity is a very powerful concept and has been observed in a variety of experimental settings, such as E. coli  \citep{Elowitz:2002hb} and stem cell reprogramming \citep{Hanna:2009ix}. Since stochastic transitions, occur on a single-cell level, at any time during a transition the cell population as a whole exists as a mixture of states. Moreover the exact composition of this mixture changes over time. Any measurements performed on homogenates\footnote{mixture obtained from mechanically broken down cells} from this population results in population averages with unknown composition. Trivially the best strategy would be to measure at the single-cell level. Despite advancements in genome-wide single-cell measurements \citep{deSouza:2012dz, Tang:2011gt} there remain challenges including limited availability of such data and limits to the number of genes that can be measured. Furthermore such measurements do not allow live tracking of cells and in fact the measurement process itself destroys cells thereby breaking continuity (i.e. the next measurement is on a different set of cells). These are the reasons for an incomplete understanding of transition processes. Therefore understanding transformation processes from aggregated data is important.

Inevitably an important question arises here about our definition of states in the transformation. There are many ways to approach this and an obvious approach is to define states in a biological sense, but there is no consensus on a biologically motivated definition of a state. In a biological sense a complete definition of a state would include all possible information regarding the state, if we don't include the different stages of the cell cycle as distinct states we have to define an area in this complex space as some changes in the cell will be due to inherent noise or the cell cycle. In most cases not all information is available or is limited due to cost. In this work when we talk about states we are referring to changes in gene expression to a number of genes across the genome.

The study of stem cell reprogramming plays an important role in the development of personalised medicine, which in its extreme would allow the regrowth of whole organs to replace damaged ones. This could circumvent any issues arising from treatments derived using foreign cells, as treatments would originate from the patients own cells. Work carried out in this field has yielded the development of techniques that allow the development of neurons from embryonic stem cells \citep{Vierbuchen:2010fa, Pang:2011ce} or creating muscle cells \citep{Ieda:2010ir, Efe:2011bpa}. These processes could become even more powerful when the starting point is a differentiated cell harvested from the patient \citep{Takahashi:2006hi}. There are still unanswered questions in this field about the differences of cells derived from differentiated cells to cells derived directly from embryonic stem cells \citep{Carey:2011bs, Bock:2011kx}. A better understanding of the transformation process would help in identifying issues and could propose potential ways of improving the transformation process.

Cancer is a disease so prevalent in modern society that in the UK the life time chance of contracting cancer is more than one in three \citep{Sasieni:2011}. The disease has its source in multiple genetic mutations causing changes to natural cell functions such as cell proliferation and apoptosis\footnote{programmed cell-death} which transforms cells from a healthy state to a cancerous state. These mutations code for proteins that are implicated in the eight hallmarks of cancer \citep{Hanahan:2011gu}. The hallmarks are the circumvention for the need of external growth signals; cells are unaffected by external growth-inhibition signals; evasion of apoptosis; unlimited replication; the potential to create additional blood vessels from existing ones; invasion of other tissue types; energy management of the cell and avoiding the bodies immune response. Understanding the transformation process that changes a healthy cell population to a cancerous one would allow intervention target at specific genes and proteins.

The cell cycle is central to the proliferation of cells and hence plays a key role in both transformations mentioned above. In fact mutations that can lead to cancer can be acquired during the cell cycle as this is the process during which DNA is replicated and the replication process can at times lead to errors. In a normal cell there are multiple checks that prevent such errors from propagating, but in an unhealthy cell genes central to these processes are mutated leading to malfunctions. Radiation plays an important role in the cell as it can be a cause of mutations and is also used as treatment to kill unhealthy cells; damage to DNA can lead to apoptosis during the cell cycle. Radiation effects on the cell includes changes in gene expression and is also related to radiation strength \citep{Gentile:2003in}. Some cells will arrest in the cell cycle after radiation damage either leading to apoptosis or a brief pause in the cell cycle followed by a re-entry to the cell cycle \citep{Pawlik2004928}. Understanding the mechanism that leads to the different responses is key in treatment as well as prevention of cancer.

In this thesis we attempt to learn single-cell level information from homogenate population averaged data of various types. We especially focus on gene expression and the role of genes in transformation. We take a data driven approach where model parameters are estimated by comparison to data. The first model we use is based on latent Markov processes aggregated over cells using a least squares estimation; it takes inspiration from the success in application of latent variable models such as hidden Markov models (HMMs) to hidden transitions in biology and genomics \citep{Yoon:2009dl,Ernst:2012iia}. The second model uses simple statistical principles for the derivation of the model and Monte Carlo integration to approximate an integral. These are simple models that allow investigation of complicated biological processes.

Chapter \ref{cha:stamm} starts with the description of a model called \emph{State Transitions using Aggregated Markov Models} (STAMM) based on previous work by \cite{Armond:2013}; a latent stochastic process that obtains state-specific gene expression data as well as number of intermediate states from homogenate population time courses. Previous models exist that endeavour to achieve this such as deconvolving the cell cycle \citep{Bar-Joseph04082004}; dissecting expression data with known mixtures \citep{Lahdesmaki:2005fh}; or a hidden Markov model to determine expression levels and fractions of cells in each population \citep{Roy:2006ik}. Even though all such methods have strengths they also contain weaknesses addressed by STAMM. First, it provides single-cell level description of the transformations process and just like in the real system this process is hidden from observation due to averaging over multiple realisations (or cells). Second, in our model the latent process is in continuous time and therefore it does not have any need for special techniques to deal with missing data and unevenly distributed measurements. Third, the model relies on very few assumptions such as fractions of mixtures; it estimates all parameters from data. We also discuss in this Chapter a single-cell level simulation process which is used to test the model properties and assumptions. Then we also outline a computationally efficient model selection procedure following and expanding on previous work by \cite{Armond:2013}. Results show that parameter estimation works well even when violating assumptions. Only strong violations make estimations difficult and in this setting transition rates in particular are not estimated well.

Chapter \ref{cha:oncog-transf} describes an application of STAMM to RNA-seq time course data of an oncogenic transformation using a healthy breast cell line (MCF-10A) as the initial population. We outline the pre-processing steps needed to apply the model to RNA-seq data. Since observations are made as counts it is often considered that a Poisson distribution or a negative binomial distribution is the most fitting to such data. However we argue that once data has been pre-processed to allow for comparison between independent samples the data are no longer truly counts, but rather can be usefully treated as continuous. Then we show application of STAMM and show that it can be applied to large data sets in a relatively short computational time.

Chapter \ref{cha:stem-cells} briefly discusses results from applying STAMM to a microarray time course. This is obtained by  reprogramming of secondary Mouse embryonic fibroblast (MEF) cells to induced pluripotent stem cells. Then we show a possible next step once parameters have been obtained by STAMM. This step includes comparison of estimated parameters to new single-cell measurements which in this case were carried out on a different reprogramming system \citep{Buganim:2012hp}. We show that results are comparable despite measurements being made on different systems and using different methods.

Chapter \ref{cha:cell-cycle} derives a model to investigate a slightly different system where less data is available and serves as a proof of concept since data was not available in time for this thesis. The gene expression is measured at the initial time point and the cell population is subject to a stimulus of various strength. At a later time fractions of cells in two distinct states are obtained by counting individual cells. An example of such a system is a population of cells radiated during the cell cycle upon which some go into arrest leading to apoptosis and some re-enter the cell cycle at a later time. This process is believed to be dependant on heterogeneity at the initial time point. This model attempts to assign a weight to each gene signifying its importance to the transformation process. Then we outline a single-cell simulation procedure and apply the model to a single gene simulation and a four gene simulation. Results show that high noise level makes it difficult to estimate parameters but at low noise levels parameters are estimated reasonably well allowing us to at a least distinguish between genes that are important for transformation to ones that are not.

\vspace*{2cm}
\noindent Novel contributions of this thesis are listed below:
\begin{itemize}
\item {\bf Chapter \ref{cha:stamm}}
\begin{itemize}
\item Single-cell simulation study. We present a simulation frame-work imitating the biological single-cell processes; single-cells undergo random transition between states and observed expressions are an average over cells. The strength of this approach is that single-cell state specific parameters for data generation are known. Therefore we can empirically test estimation of parameters as well as the selection of correct number of states. It also allows us to check estimation under violation of model assumptions and additionally we can empirically investigate identifiability of the model.

\item Full investigation of estimation, including tuning parameters. We discuss and verify with simulations parameter estimation including setting tuning parameters using an unbiased approach. This is followed by sensitivity analysis performed for tuning parameters.

\item Computationally efficient model selection. For STAMM to be useful, an unbiased estimation of model parameters, especially the number of states, is important. We put forward a simple approach which uses a form of cross-validation to determine number of states and other model parameters. We show that this method is effective during simulation and computationally efficient.

\item Implementation in R. We wrote a package for the STAMM model in R including a simulated data set, published at \url{https://github.com/anasrana/stamm}.

\end{itemize}

\item {\bf Chapter \ref{cha:oncog-transf}}

\begin{itemize}
\item Application of STAMM to RNA-seq time-course data.
We show, using an example, how STAMM is able to analyse sequencing time-course data. The example we chose is using RNA-seq data from an {\it in vitro} study of oncogenic transformation of a healthy breast cancer cell line (MCF-10A) under induction of the oncogene {\it src}.

\end{itemize}
\item {\bf Chapter \ref{cha:stem-cells}}
  \begin{itemize}
  \item Comparing estimation to single-cell measurements for stem cell reprogramming. In this Chapter the main contribution is firstly, computational i.e. ensuring that estimation was reproducible as well as determining sensitivity of Bayesian model selection to the choice of hyper-parameters. Secondly, a comparison of estimated parameters from STAMM to single-cell level measurements taken at different time points.
  \end{itemize}

\item {\bf Chapter \ref{cha:cell-cycle}}
  \begin{itemize}
  \item Proof of concept of a novel model. Here, we introduce a new model to understand the importance of genes for radiation response. The gene expression is only measured for the initial population subsequent measurements are fractions of cells transforming at different radiation doses.We also outline a single-cell simulation set-up and a brief application of the model to simulated data.
  \end{itemize}
\end{itemize}



%%% Local Variables:
%%% TeX-master: "warwickthesis"
%%% End:
